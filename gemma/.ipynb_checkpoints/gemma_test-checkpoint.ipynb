{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e518ecb7-86aa-4b27-890d-15854eba3fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hf_token = os.environ['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2e0e3c-45e8-4dd3-8dff-f01e485239b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb040053-1ba1-4c40-b47a-9a02af97094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "quantization_config = transformers.QuantoConfig(weights=\"int8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea259fe-3179-4702-b9d9-45f44be8515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42001f0b98504c2492b60ae903b895f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = transformers.pipeline(\n",
    "    # \"image-text-to-text\",\n",
    "    \"text-getneration\",\n",
    "    model=\"google/gemma-3-4b-it\",\n",
    "    device_map=\"auto\",\n",
    "    model_kwargs = {\n",
    "        \"quantization_config\" : quantization_config\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91e01d0-7c7c-482b-8c54-3b9c52bfc047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.31231 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG\"},\n",
    "            {\"type\": \"text\", \"text\": \"나는 어디로 가야할까? 내 앞에는 상자가 있고, 내 오른쪽에는 아무것도 없어, 내 왼쪽에는 길이 있어\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "output = pipe(text=messages, max_new_tokens=200)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"{end - start:.5f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b6498b-1c06-42fc-a9f3-87be7d2a68c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_text': [{'role': 'system',\n",
       "    'content': [{'type': 'text', 'text': 'You are a helpful assistant.'}]},\n",
       "   {'role': 'user',\n",
       "    'content': [{'type': 'image',\n",
       "      'url': 'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG'},\n",
       "     {'type': 'text',\n",
       "      'text': '나는 어디로 가야할까? 내 앞에는 상자가 있고, 내 오른쪽에는 아무것도 없어, 내 왼쪽에는 길이 있어'}]}],\n",
       "  'generated_text': [{'role': 'system',\n",
       "    'content': [{'type': 'text', 'text': 'You are a helpful assistant.'}]},\n",
       "   {'role': 'user',\n",
       "    'content': [{'type': 'image',\n",
       "      'url': 'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG'},\n",
       "     {'type': 'text',\n",
       "      'text': '나는 어디로 가야할까? 내 앞에는 상자가 있고, 내 오른쪽에는 아무것도 없어, 내 왼쪽에는 길이 있어'}]},\n",
       "   {'role': 'assistant',\n",
       "    'content': '사진에 따르면, 당신은 상자 쪽으로 가야 합니다. 상자는 당신이 가는 곳으로 이어진 길을 안내하고 있습니다.'}]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9110b8-c94d-4721-b93c-c4e2f43391c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
