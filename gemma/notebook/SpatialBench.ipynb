{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e518ecb7-86aa-4b27-890d-15854eba3fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iamjunhee/gemma_test/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a9f797-899c-4f88-8422-deac788b394b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1fdfd1e901424b886909e957adfd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junhee0110/.agricsense/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "\n",
    "USE_PLAIN = True\n",
    "\n",
    "if USE_PLAIN:\n",
    "    model_path = \"google/gemma-3-4b-it\"\n",
    "else:\n",
    "    model_path = \"./agricsense.model\"\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21029137-b6d0-46cb-a198-d88fdcf8d3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 20 examples [00:00, 1114.47 examples/s]\n",
      "Generating train split: 40 examples [00:00, 4780.92 examples/s]\n",
      "Generating train split: 34 examples [00:00, 4701.20 examples/s]\n",
      "Generating train split: 40 examples [00:00, 6503.05 examples/s]\n",
      "Generating train split: 40 examples [00:00, 7003.64 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "DATASET_BASE = \"/home/iamjunhee/OhMyData/SpatialBench\"\n",
    "TEST_ITEMS = [\"counting\", \"existence\", \"positional\", \"reach\", \"size\"]\n",
    "DATA_PER_ITEM = 5\n",
    "\n",
    "get_json_dir = lambda item: os.path.join(DATASET_BASE, \"{}.json\".format(item))\n",
    "\n",
    "dataset = [load_dataset(\"json\", data_files=get_json_dir(item), split=\"train\") for item in TEST_ITEMS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "206c6fd8-caa6-4854-8d72-df9e02ea29b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(rel_path, is_depth):\n",
    "    path_split = rel_path.split(\"/\")\n",
    "\n",
    "    if is_depth:\n",
    "        path_split[0] += \"_d\"\n",
    "        file_name = path_split[1].split(\".\")\n",
    "        file_name[-1] = \"png\"\n",
    "        path_split[-1] = \".\".join(file_name)\n",
    "\n",
    "    return os.path.join(DATASET_BASE, *path_split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f10b5843-5366-458e-aad6-ed6eb61ad3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_sample_from_dataset(dataset, seed, N = 5):\n",
    "    result = []\n",
    "    random.seed(seed)\n",
    "    for item in dataset:\n",
    "        result += random.sample(list(item), N)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "171744c5-f865-401b-8bd7-1c562e0c2c79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'USE_PLAIN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_prompt, generate, generate_prompt_with_context\n\u001b[32m      3\u001b[39m bench_sample = get_sample_from_dataset(dataset, \u001b[32m5\u001b[39m)\n\u001b[32m      5\u001b[39m prompt = [\n\u001b[32m      6\u001b[39m     generate_prompt(sample[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m                     get_image_path(sample[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m], is_depth = \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m                     \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mUSE_PLAIN\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m get_image_path(sample[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m], is_depth = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m     ) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m bench_sample\n\u001b[32m     10\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'USE_PLAIN' is not defined"
     ]
    }
   ],
   "source": [
    "from pipeline import generate_prompt, generate, generate_prompt_with_context\n",
    "\n",
    "bench_sample = get_sample_from_dataset(dataset, 5)\n",
    "\n",
    "prompt = [\n",
    "    generate_prompt(sample[\"question\"],\n",
    "                    get_image_path(sample[\"image\"], is_depth = False),\n",
    "                    None if USE_PLAIN else get_image_path(sample[\"image\"], is_depth = True)\n",
    "    ) for sample in bench_sample\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06bf6a-70b4-4398-b45f-d5930159932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batch = lambda data, batch_size: [data[i:i+batch_size] for i in range (0, len(data), batch_size)]\n",
    "\n",
    "batched_prompt = create_batch(prompt, 5)\n",
    "answers = []\n",
    "\n",
    "for item in batched_prompt:\n",
    "    generated = generate(item, model, processor, max_new_tokens=100)[\"generated\"]\n",
    "    answers+=generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44161c0b-7ef8-424c-8653-a0c8a5885852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "bench_result = deepcopy(bench_sample)\n",
    "\n",
    "for index in range(len(bench_result)):\n",
    "    bench_result[index][\"generated\"] = answers[index]\n",
    "\n",
    "print(json.dump(bench_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
